{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Algoritmo  Acurácia\n",
      "0                Perceptron  0.959064\n",
      "1                Adaline GD  0.877193\n",
      "2               Adaline SGD  0.970760\n",
      "3  Adaline SGD (mini-batch)  0.941520\n",
      "4      Perceptron (Sklearn)  0.959064\n",
      "5                       SGD  0.964912\n",
      "6       Logistic Regression  0.982456\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carregar o dataset\n",
    "data_path = \"wdbc.data\"\n",
    "names_path = \"wdbc.names\"\n",
    "\n",
    "column_names = ['ID', 'Diagnosis', 'mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area', 'mean_smoothness',\n",
    "                'mean_compactness', 'mean_concavity', 'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
    "                'radius_SE', 'texture_SE', 'perimeter_SE', 'area_SE', 'smoothness_SE', 'compactness_SE', 'concavity_SE',\n",
    "                'concave_points_SE', 'symmetry_SE', 'fractal_dimension_SE', 'radius_worst', 'texture_worst',\n",
    "                'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
    "                'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
    "data = pd.read_csv(data_path, header=None, names=column_names)\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Algoritmo Perceptron\n",
    "perceptron = Perceptron(random_state=42)\n",
    "perceptron.fit(X_train, y_train)\n",
    "y_pred_perceptron = perceptron.predict(X_test)\n",
    "accuracy_perceptron = accuracy_score(y_test, y_pred_perceptron)\n",
    "\n",
    "# Algoritmo Adaline com Gradiente Descendente\n",
    "adaline_gd = SGDClassifier(loss='perceptron', random_state=42)\n",
    "adaline_gd.fit(X_train, y_train)\n",
    "y_pred_adaline_gd = adaline_gd.predict(X_test)\n",
    "accuracy_adaline_gd = accuracy_score(y_test, y_pred_adaline_gd)\n",
    "\n",
    "# Algoritmo Adaline com Gradiente Descendente Estocástico\n",
    "adaline_sgd = SGDClassifier(loss='log_loss', random_state=42)  # Alteração do parâmetro 'loss'\n",
    "adaline_sgd.fit(X_train, y_train)\n",
    "y_pred_adaline_sgd = adaline_sgd.predict(X_test)\n",
    "accuracy_adaline_sgd = accuracy_score(y_test, y_pred_adaline_sgd)\n",
    "\n",
    "# Algoritmo Adaline com Gradiente Descendente Estocástico usando mini-batches\n",
    "batch_size = 20\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "adaline_sgd_mini_batch = SGDClassifier(loss='log_loss', random_state=42)  # Alteração do parâmetro 'loss'\n",
    "\n",
    "for batch in range(n_batches):\n",
    "    start = batch * batch_size\n",
    "    end = start + batch_size\n",
    "    adaline_sgd_mini_batch.partial_fit(X_train[start:end], y_train[start:end], classes=np.unique(y_train))\n",
    "\n",
    "y_pred_adaline_sgd_mini_batch = adaline_sgd_mini_batch.predict(X_test)\n",
    "accuracy_adaline_sgd_mini_batch = accuracy_score(y_test, y_pred_adaline_sgd_mini_batch)\n",
    "\n",
    "# Algoritmo Perceptron do Scikit Learn\n",
    "perceptron_sklearn = Perceptron(random_state=42)\n",
    "perceptron_sklearn.fit(X_train, y_train)\n",
    "y_pred_perceptron_sklearn = perceptron_sklearn.predict(X_test)\n",
    "accuracy_perceptron_sklearn = accuracy_score(y_test, y_pred_perceptron_sklearn)\n",
    "\n",
    "# Algoritmo Stochastic Gradient Descent (SGD) do Scikit Learn\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "accuracy_sgd = accuracy_score(y_test, y_pred_sgd)\n",
    "\n",
    "# Algoritmo Logistic Regression do Scikit Learn\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred_logistic_regression = logistic_regression.predict(X_test)\n",
    "accuracy_logistic_regression = accuracy_score(y_test, y_pred_logistic_regression)\n",
    "\n",
    "# Comparação dos resultados\n",
    "results = pd.DataFrame({\n",
    "    'Algoritmo': ['Perceptron', 'Adaline GD', 'Adaline SGD', 'Adaline SGD (mini-batch)',\n",
    "                  'Perceptron (Sklearn)', 'SGD', 'Logistic Regression'],\n",
    "    'Acurácia': [accuracy_perceptron, accuracy_adaline_gd, accuracy_adaline_sgd,\n",
    "                 accuracy_adaline_sgd_mini_batch, accuracy_perceptron_sklearn, accuracy_sgd,\n",
    "                 accuracy_logistic_regression]\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
